{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Detecting Dog Emotions Using Deep Learning\n\n**Objective**: Build a convolutional neural network to predict whether a dog is happy, sad, or relaxed based on its picture.\n\nDog dataset used from Flickr.\n\n## Table of Contents\n- [1. Understanding the image data and creating dataset labels](#1)\n- [2. Creating a PyTorch Dataset](#2)\n- [3. Splitting the Training and Test Data](#3)\n- [4. Building the Convolutional Neural Network](#4)\n- [5. Training the Convolutional Neural Network](#5)\n- [6. What are our generated predictions?](#6)","metadata":{}},{"cell_type":"markdown","source":"<a name =\"1\"> </a>\n## 1. Understanding the image data and creating dataset labels","metadata":{}},{"cell_type":"code","source":"IMAGE_DIR = \"../input/images/images\"\nFOLDERS = [\"happy\", \"sad\", \"relaxed\"]\nDEVICE = \"mps\"","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:00:58.195523Z","iopub.execute_input":"2022-10-04T11:00:58.196464Z","iopub.status.idle":"2022-10-04T11:00:58.202498Z","shell.execute_reply.started":"2022-10-04T11:00:58.196419Z","shell.execute_reply":"2022-10-04T11:00:58.201357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:00:58.204440Z","iopub.execute_input":"2022-10-04T11:00:58.204805Z","iopub.status.idle":"2022-10-04T11:00:58.215405Z","shell.execute_reply.started":"2022-10-04T11:00:58.204773Z","shell.execute_reply":"2022-10-04T11:00:58.214313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_files = []\nlabels = [] #text labels\nlabel_code = [] #text labels to actual binary code\n\nfor folder in FOLDERS:\n    fname = os.path.join(IMAGE_DIR, folder)\n    #joins together the directory name 'images' and the folder name with emotions\n    \n    for im in os.listdir(fname):\n        impath = os.path.join(fname, im)\n        img_files.append(impath)\n        labels.append(folder)\n        label_code.append(FOLDERS.index(folder))","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:00:58.217550Z","iopub.execute_input":"2022-10-04T11:00:58.218229Z","iopub.status.idle":"2022-10-04T11:00:59.190475Z","shell.execute_reply.started":"2022-10-04T11:00:58.218194Z","shell.execute_reply":"2022-10-04T11:00:59.189384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.DataFrame(dict(filename = img_files, label = labels, code = label_code))","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:00:59.192154Z","iopub.execute_input":"2022-10-04T11:00:59.192633Z","iopub.status.idle":"2022-10-04T11:00:59.213610Z","shell.execute_reply.started":"2022-10-04T11:00:59.192586Z","shell.execute_reply":"2022-10-04T11:00:59.212307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:00:59.216194Z","iopub.execute_input":"2022-10-04T11:00:59.216585Z","iopub.status.idle":"2022-10-04T11:00:59.243647Z","shell.execute_reply.started":"2022-10-04T11:00:59.216553Z","shell.execute_reply":"2022-10-04T11:00:59.242519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:00:59.245037Z","iopub.execute_input":"2022-10-04T11:00:59.245431Z","iopub.status.idle":"2022-10-04T11:00:59.251558Z","shell.execute_reply.started":"2022-10-04T11:00:59.245397Z","shell.execute_reply":"2022-10-04T11:00:59.250110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(0) #to generate numbers in random order ","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:00:59.253195Z","iopub.execute_input":"2022-10-04T11:00:59.253589Z","iopub.status.idle":"2022-10-04T11:00:59.270377Z","shell.execute_reply.started":"2022-10-04T11:00:59.253556Z","shell.execute_reply":"2022-10-04T11:00:59.268780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(DEVICE) #intializing the torch device; mine is a CPU","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:00:59.271866Z","iopub.execute_input":"2022-10-04T11:00:59.272554Z","iopub.status.idle":"2022-10-04T11:00:59.277895Z","shell.execute_reply.started":"2022-10-04T11:00:59.272503Z","shell.execute_reply":"2022-10-04T11:00:59.276752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name = \"2\"></a>\n## 2. Creating a PyTorch Dataset","metadata":{}},{"cell_type":"code","source":"from torchvision.io import read_image\nfrom torchvision import transforms as T\nfrom torch.utils.data import Dataset\nimport math","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:00:59.279450Z","iopub.execute_input":"2022-10-04T11:00:59.279920Z","iopub.status.idle":"2022-10-04T11:00:59.585623Z","shell.execute_reply.started":"2022-10-04T11:00:59.279869Z","shell.execute_reply":"2022-10-04T11:00:59.584634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DogDataset(Dataset):\n    def __init__(self, dataset):\n        self.dataset = dataset\n        self.augments = [T.RandomHorizontalFlip(1), T.RandomRotation(90), T.AutoAugment()]\n        self.normalize = T.Compose([\n            T.ConvertImageDtype(torch.float),\n            #apply multiple transformations in order and change the image integers to float\n            T.Normalize((.485, .456, .406), (.229, .224, .225))\n            #standardize the image intensities and SDs of the dataset into a range\n            #the numbers above are used to normalize against imagenet, a popular dataset\n        ])\n    def __len__(self):\n        return self.dataset.shape[0] * (len(self.augments) + 1)\n    \n    def classes(self):\n        return self.dataset[\"code\"].unique() #return the number of unique labels from the dataset\n    \n    def __getitem__(self, idx):\n        augment = math.floor(idx / self.dataset.shape[0])\n        idx = idx % self.dataset.shape[0] #ensuring the index is within the original number of rows\n        \n        row = self.dataset.iloc[idx,:]\n        \n        img_path = row[\"filename\"]\n        image = read_image(img_path)\n        \n        label = row[\"code\"]\n        if augment > 0:\n            image = self.augments[augment - 1].forward(image)\n            \n        image = self.normalize(image)\n        \n        return image, int(label), img_path;","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:00:59.588763Z","iopub.execute_input":"2022-10-04T11:00:59.589110Z","iopub.status.idle":"2022-10-04T11:00:59.600009Z","shell.execute_reply.started":"2022-10-04T11:00:59.589079Z","shell.execute_reply":"2022-10-04T11:00:59.598998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = DogDataset(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:00:59.601010Z","iopub.execute_input":"2022-10-04T11:00:59.601338Z","iopub.status.idle":"2022-10-04T11:00:59.612762Z","shell.execute_reply.started":"2022-10-04T11:00:59.601309Z","shell.execute_reply":"2022-10-04T11:00:59.611822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name = \"3\"></a>\n## 3. Splitting the Training and Test Data","metadata":{}},{"cell_type":"code","source":"train_size = int(0.8 * len(data))\ntest_size = len(data) - train_size\n\ntrain_data, test_data = torch.utils.data.random_split(data, [train_size, test_size], generator = torch.Generator().manual_seed(1))\n# random split and the generator to set consistency in order and so that the same values will be\n# assigned to both train & test sets","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:00:59.614290Z","iopub.execute_input":"2022-10-04T11:00:59.615355Z","iopub.status.idle":"2022-10-04T11:00:59.634937Z","shell.execute_reply.started":"2022-10-04T11:00:59.615318Z","shell.execute_reply":"2022-10-04T11:00:59.633668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader #load the data as we train the DL model\nBATCH_SIZE = 64 #number of images to be used for training at one instant\nEPOCHS = 50 #number of times I'll feed these images to train my model\ntrain = DataLoader(train_data, batch_size = BATCH_SIZE, shuffle = True)\ntest = DataLoader(test_data, batch_size = BATCH_SIZE, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:00:59.636531Z","iopub.execute_input":"2022-10-04T11:00:59.637062Z","iopub.status.idle":"2022-10-04T11:00:59.644629Z","shell.execute_reply.started":"2022-10-04T11:00:59.637015Z","shell.execute_reply":"2022-10-04T11:00:59.643179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name = \"4\"></a>\n## 4. Building the Convolutional Neural Network","metadata":{}},{"cell_type":"code","source":"#creating a new class for the neural network\n\nfrom torch import nn\nclass NeuralNetwork(nn.Module):\n    def __init__ (self, classes):\n        super(NeuralNetwork, self).__init__()\n        \n        #creating the nn layers\n        self.bn = nn.BatchNorm2d(64) ##normalize values in a batch to prevent overfitting & make training faster\n        \n        #building the network layer-by-layer inside this sequential container\n        self.cnn = nn.Sequential(\n            nn.Conv2d(3, 64, 4, stride = 2), #look at a 4x4 slice, move over 2 pixels, and do it again and again\n            self.bn,\n            nn.ReLU(True),\n            \n            nn.MaxPool2d(2, 2), #shrink the dimensionality of each of our 64 channels to make the algorithm stable\n            \n            nn.Conv2d(64, 64, 2),\n            self.bn,\n            \n            nn.Conv2d(64, 64, 2),\n            self.bn,\n            nn.ReLU(True),\n            \n            nn.MaxPool2d(2, 2)\n            \n        )\n        \n        self.dense = nn.Sequential(\n            nn.Linear(64 * 46 * 46, 64),\n            nn.Linear(64, len(classes))\n        )\n    \n    def forward(self, x):\n        x = self.cnn(x) #apply convolutional network to a batch of images (64 of them)\n        x = torch.flatten(x, 1) #then we flatten the layers and create a 1 single list of vector\n        x = self.dense(x) #then we pass that into the dense layer for prediction\n        return x;","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:05:24.664825Z","iopub.execute_input":"2022-10-04T11:05:24.665292Z","iopub.status.idle":"2022-10-04T11:05:24.677595Z","shell.execute_reply.started":"2022-10-04T11:05:24.665234Z","shell.execute_reply":"2022-10-04T11:05:24.676241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = data.classes()\nlabels","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:05:29.649949Z","iopub.execute_input":"2022-10-04T11:05:29.651053Z","iopub.status.idle":"2022-10-04T11:05:29.658939Z","shell.execute_reply.started":"2022-10-04T11:05:29.651009Z","shell.execute_reply":"2022-10-04T11:05:29.657737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we'll now define our model by passing in our labels and sending the outputted class predictions to the device\n\nmodel = NeuralNetwork(labels).to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:05:32.692071Z","iopub.execute_input":"2022-10-04T11:05:32.692481Z","iopub.status.idle":"2022-10-04T11:05:32.763583Z","shell.execute_reply.started":"2022-10-04T11:05:32.692447Z","shell.execute_reply":"2022-10-04T11:05:32.762481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name = \"5\"></a>\n## 5. Training the Convolutional Neural Network","metadata":{}},{"cell_type":"code","source":"#generating a loss function\n\nloss_fn = nn.CrossEntropyLoss()\n\n#optimize the weights of the nn against the loss function\noptimizer = torch.optim.SGD(model.parameters(), lr = .001)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:05:38.367428Z","iopub.execute_input":"2022-10-04T11:05:38.367839Z","iopub.status.idle":"2022-10-04T11:05:38.373856Z","shell.execute_reply.started":"2022-10-04T11:05:38.367807Z","shell.execute_reply":"2022-10-04T11:05:38.372582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"size = len(train.dataset)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:05:40.758459Z","iopub.execute_input":"2022-10-04T11:05:40.758897Z","iopub.status.idle":"2022-10-04T11:05:40.764623Z","shell.execute_reply.started":"2022-10-04T11:05:40.758861Z","shell.execute_reply":"2022-10-04T11:05:40.763228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loop to train the nn\n\nfor epoch in range(EPOCHS):\n    for batch, (images, labels, img_paths) in enumerate(train):\n        optimizer.zero_grad()\n        \n        images = images.to(device)\n        predictions = model(images.float())\n        labels = labels.to(device)\n        loss = loss_fn(predictions, labels)\n        \n        loss.backward() #backward propagation so that optimizer can try again to improve weights and improve loss\n        optimizer.step()\n    \n    loss = loss.item()\n    print(f\"loss: {loss:>7f} [{epoch}]\")","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:01:17.401441Z","iopub.execute_input":"2022-10-04T11:01:17.402748Z","iopub.status.idle":"2022-10-04T11:01:20.893413Z","shell.execute_reply.started":"2022-10-04T11:01:17.402677Z","shell.execute_reply":"2022-10-04T11:01:20.891239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'dog_model.pth')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name = \"6\"> </a>\n## 6. What are our generated predictions?","metadata":{}},{"cell_type":"code","source":"model = torch.load('../input/trained-dog-model/dog_model.pth')","metadata":{"execution":{"iopub.status.busy":"2022-10-04T11:05:46.987206Z","iopub.execute_input":"2022-10-04T11:05:46.987661Z","iopub.status.idle":"2022-10-04T11:05:47.162029Z","shell.execute_reply.started":"2022-10-04T11:05:46.987625Z","shell.execute_reply":"2022-10-04T11:05:47.160063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_preds = list() #make predictions against our training set\nall_labels = list()\nall_paths = list()\n\nwith torch.no_grad(): #we are in inference mode with this\n    for batch, (images, labels, img_paths) in enumerate(test): #looping through our test data\n        \n        images = images.to(device)\n        outputs = model(images.float())\n        \n        _, preds = torch.max(outputs.data, 1) #gives a class that is the most predictive for each image\n        \n        all_labels.append(labels)\n        all_preds.append(preds)\n        all_paths.append(img_paths)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\npreds = np.concatenate([p.cpu().numpy() for p in all_preds])\nlabels = np.concatenate([p.cpu().numpy() for p in all_labels])\npaths = np.concatenate([p for p in all_paths])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we can now get our exact match accuracy by:\n((preds == labels).sum()) / len(labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#figuring out the accuracy for each class\npredictions = pd.DataFrame(dict(pred=preds, label=labels, path=paths))\npredictions[\"correct\"] = (predictions[\"pred\"] == predictions[\"label\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert the prediction code of 0, 1, 2 to a label\npredictions[\"prediction\"] = predictions[\"pred\"].apply(lambda x: FOLDERS[int(x)])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions[\"actual\"] = predictions[\"label\"].apply(lambda x: FOLDERS[int(x)])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions.groupby(\"prediction\").apply(lambda x: x[\"correct\"].sum() / x.shape[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disp = predictions.iloc[:30,:].copy()\ndisp","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#show the image\ndef image_formatter(path):\n    return f'<img src=\"{path}\">'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#style our database using this function\ndisp.style.format({'path': image_formatter})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***We can still improve the accuracy of our model by some simple techniques such as getting more pictures, use a more complex and deeper neural network, augment the dataset more, and increase the epochs. However, my computer has barely scraped by while only training the network so I'll stop this here.***","metadata":{}}]}